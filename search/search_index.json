{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to snow_pc","text":"<p>A python package for automated processing of point clouds to simplify elevation creation, co-registration and differencing to facilitate the production of snow depth and vegetation products.</p> <ul> <li>Free software: MIT license</li> <li>Documentation: https://Surfix.github.io/snow_pc</li> </ul>"},{"location":"#introduction-and-statement-of-need","title":"Introduction and statement of Need","text":"<p>Light Detection and Ranging (LiDAR) and Structure from Motion (SfM) photogrammetry currently provide the most advanced and accurate approaches for monitoring snow distribution across a range of platforms, scales, and repeat intervals. These techniques generate high-resolution digital elevation models (DEMs) by producing georeferenced point clouds from overlapping imagery in the case of photogrammetry or from high frequency laser pulses in the case of LiDAR. However, post-processing of point clouds for generation of snow depth rasters remains complex compared to many other earth science applications such as topographic mapping, vegetation monitoring, geomorphology and landform analysis. Existing point cloud processing software suite such as Point Data Abstraction Library (PDAL) and LAStools provide general purpose tools for pre-processing, filtering and analyzing large point cloud data. Yet, there is a lack of tool that leveraged these capacities for optimized automated workflows specifically tailored for snow and ice applications. Consequently, complex manual interventions are often required for tasks like merging point cloud files from different flight lines or acquisitions, point clouds filtering, construction of (DTMs), aligning the DTMs and generation of products. This hinders efficient production of snow depth and limits full utilization of rich information in point clouds datasets.  </p> <p>snow_pc addresses this challenge by leveraging pdal and Stereo Pipeline (ASP) to automate point clouds management in a standardized workflow for generating elevation models, snow depths and vegetation products. This allows diverse users of developers, data processors and snow scientists to automate core point clouds processing tasks like merging, coordinate transformations, classification, co-registration and rasterization to simplify effort and facilitate multi-temporal analysis.</p>"},{"location":"#usage","title":"Usage","text":"<p>To install snow_pc, run this command:</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install leafmap\n</code></pre> <p>You can also install from sources with this command:</p> <pre><code>pip install git+https://github.com/Surfix/snow-pc\n</code></pre>"},{"location":"#preparing-point-clouds-for-processing","title":"Preparing point clouds for processing","text":"<p>The core module, snow_pc, features the prepare_pc function, which handles preprocessing tasks like removing whitespace from files, converting LAS to LAZ format, and merging files within a directory.</p> <pre><code>from snow_pc import prepare_pc\nprepare_pc('project_dir')\n</code></pre> <p>This function returns the path to the processed point clouds. Additional filtering can be applied using functions from the filtering.py module. </p> <p><pre><code>from snow_pc.filtering import return_filtering, elm_filtering, outlier_filtering, dem_filtering, ground_segmentation\nreturn_filtering('unfiltered_merge.laz')\ndem_filtering('returns_filtered.laz', 'dem.tif', dem_low= 10, dem_high=50)\nelm_filtering('dem_filtered.laz')\noutlier_filtering('elm_filtered.laz', multiplier=2.5)\nground_segmentation('outlier_filtered.laz')\n</code></pre> Intermittent results of DTM pipeline workflow for a track. The original point cloud is shown in top left. Point clouds after removal of invalid return is shown in top right. Bottom left is applying dem filter while the bottom right is the ground segmented points. Dem filter effectively removes noise in the point cloud such that no point is left for elm and outlier filter.</p> <p>However, users can move on to generating elevation models and the necessary filtering will be applied as required. </p>"},{"location":"#generating-dems-and-dsms","title":"Generating DEMs and DSMs","text":"<p>snow_pc module provides a pc2uncorrectedDEM for generating Digital Terrain Models and Digital Surface Models from point cloud file in a single code call.</p> <pre><code>from snow_pc import pc2uncorrectedDEM\ndtm_tif, dtm_laz, dtm_laz, dsm_laz = pc2uncorrectedDEM('project_dir')\n</code></pre>"},{"location":"#aligning-point-clouds","title":"Aligning Point Clouds.","text":"<p>The <code>laz_align</code> function of the <code>align</code> module can be used to align a point cloud to a reference surface. </p> <pre><code>from snow_pc.align import laz_align`\naligned_laz = laz_align('project_dir')\n</code></pre> <p>The entire workflow can be accomplished in one line of code: <pre><code>from snow_pc import snowpc_pipeline\nsnowpc_pipeline(in_dir)\n</code></pre></p> <p>snow_pc builds on many GIS tools particularly leafmap, gdal, pdal and ASP so these packages are automatically available after installing snow_pc and can be used as necessary. For example, the resulting point clouds at any stage can be view using the <code>view_lidar()</code> of leafmap.</p> <p><pre><code>import leafmap\nleafmap.view_lidar('unfiltered_merge.laz', cmap=\"terrain\")\n</code></pre> </p> <p>The key features  To learn more about snow_pc, check out the snow_pc api reference on the documentation website- https://Surfix.github.io/snow-pc</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#prepare-module","title":"Prepare Module","text":"<ul> <li><code>replace_white_spaces(in_dir)</code> : remove white spaces in the point cloud files. </li> <li><code>las2laz(in_dir)</code> : Takes a user directory full of las files and convert the files to LAZ files. LAZ is a compressed version of LAS so it provides optimal data transfer and computation efficiency.</li> <li><code>merge_laz_files(in_dir)</code>: merge all LAZ files in the project directory into one LAZ file. This step is crucial for mosaicking point cloud data from different flight lines to ensure seamless coverage over the area of interest, simplify data management tasks and facilitate processing in subsequent commands that take a single point cloud file. </li> </ul>"},{"location":"#filtering-module","title":"Filtering module","text":"<ul> <li><code>return_filtering(laz_fp)</code> : removes points with invalid returns where the return number or number of returns is zero. This is only required for LiDAR point clouds. </li> <li><code>dem_filtering(laz_fp)</code> : extracts only points within a defined elevation range relative to the reference DEM. This filter is important to remove atmospheric or MTA noise from the data thereby eliminating outlier points too far above or below the ground surface.</li> <li><code>elm_filtering(laz_fp)</code> : finds isolated low points that are likely errors or noise far below the actual ground level.</li> <li><code>outlier_filtering(laz_fp)</code> : removes extreme outlier points in the point cloud that deviate significantly from surrounding points.</li> <li><code>ground_segmentation(laz_fp)</code> : Classify the terrain points using the Simple Morphological Filter (SMRF) algorithm</li> <li><code>surface_segmentation(laz_fp)</code> : Isolate the surface points from the point clouds</li> </ul>"},{"location":"#modeling-module","title":"Modeling module","text":"<ul> <li><code>terrain_models(laz_fp)</code> : Use filters.dem, filters.mongo, filters.elm, filters.outlier, filters.smrf, and filters.range to filter the point cloud for terrain models [Todo: Refactor to leverage the filtering module]</li> <li><code>surface_models(laz_fp)</code> : Use filters.dem, filters.mongo and filters.range to filter the point point cloud for surface points [Todo: Refactor to leverage the filtering module]</li> </ul>"},{"location":"#align-module","title":"Align module","text":"<ul> <li><code>clip_pc(in_laz, buff_shp)</code> : Clip the point cloud to a shapefile. [To do]</li> <li><code>align(in_laz, dem)</code>: Align the point clouds to a reference [To do]</li> </ul>"},{"location":"#product-module","title":"Product module","text":"<ul> <li><code>generate_product(dtm_file, dsm_file)</code>: Derive snow depth and canopyheight from DTM and DSM files [To do]</li> </ul>"},{"location":"#snow_pc-module","title":"Snow_pc module","text":"<ul> <li><code>prepare_pc(in_dir)</code> : Steps through all preparing tools in one call</li> <li><code>laz2uncorrectedDEM(laz_fp)</code> : steps through all tools in prepare, filtering and modeling modules to generate dtm and dsm in one call</li> <li><code>laz2correctedDEM(laz_fp)</code> : steps through all tools in prepare, filtering, modeling and aligning modules to generate co-registered dtm and dsm in one call</li> <li><code>snowpc_pipeline(in_dir)</code>: steps through all tools in prepare, filtering, modeling, align and product module to derive snow depth and vegetation height products</li> </ul>"},{"location":"#common-module","title":"Common module","text":"<ul> <li><code>download_dem(las_fp)</code> : Download DEM within the bounds of the las file.</li> </ul>"},{"location":"#todo","title":"TODO","text":"<ul> <li>[x] Add ground segmentation function to the filtering module</li> <li>[] Refactor the modeling module </li> <li>[] Refactor the clip_pc module and add pc_align function to align module (ASP does not support windows distribution???)</li> <li>[] Refactor the snow_pc module (move download_dem function to common module, Merge all steps into one call)</li> <li>[x] Complete surface segmation function to the filtering module</li> <li>[] Use a better algorithm than first return isolation for the surface_segmentation (filtering_module)</li> <li>[] Improve the segmentation accuracy for photogrammetry point clouds</li> <li>[] Add a novel approach for combining LiDAR and photogrammetry point clouds</li> <li>[] Add interactive map feature to allow users draw control surface for coregistration</li> <li>[] Implement coregistration using points</li> </ul>"},{"location":"align/","title":"snow_pc module","text":""},{"location":"align/#snow_pc.align.clip_align","title":"<code>clip_align(laz_fp, buff_shp, align_path, asp_dir, dem_is_geoid=False)</code>","text":"<p>Clip the point cloud to a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>description</p> required <code>buff_shp</code> <code>_type_</code> <p>description</p> required <code>dem_is_geoid</code> <code>_type_</code> <p>description</p> <code>False</code> <code>is_canopy</code> <code>bool</code> <p>description. Defaults to False.</p> required <p>Exceptions:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>snow_pc/align.py</code> <pre><code>def clip_align(laz_fp, buff_shp, align_path, asp_dir, dem_is_geoid = False):\n    \"\"\"Clip the point cloud to a shapefile.\n\n    Args:\n        laz_fp (_type_): _description_\n        buff_shp (_type_): _description_\n        dem_is_geoid (_type_): _description_\n        is_canopy (bool, optional): _description_. Defaults to False.\n\n    Raises:\n        Exception: _description_\n    \"\"\"\n    #set the working directory\n    in_dir = dirname(laz_fp)\n\n    #find the directory that the laz_fp is in\n\n\n    clipped_pc = join(in_dir, 'clipped_pc.laz')\n    json_fp = join(in_dir, 'jsons', 'clip_align.json')\n\n\n    # Create .json file for PDAL clip\n    json_pipeline = {\n        \"pipeline\": [\n            laz_fp,\n            {\n                \"type\":\"filters.overlay\",\n                \"dimension\":\"Classification\",\n                \"datasource\":buff_shp,\n                \"layer\":\"buffered_area\",\n                \"column\":\"CLS\"\n            },\n            {\n                \"type\":\"filters.range\",\n                \"limits\":\"Classification[22:22]\"\n            },\n            clipped_pc\n        ]\n    }\n    with open(json_fp,'w') as outfile:\n        json.dump(json_pipeline, outfile, indent = 2)\n\n    subprocess.run(['pdal', 'pipeline', json_fp])               \n\n    # Check to see if output clipped point cloud was created\n    if not exists(clipped_pc):\n        raise Exception('Output point cloud not created')\n\n    # set the dem file path\n    dem_fp = join(in_dir, 'dem.tif')\n    ref_dem = dem_fp\n\n    #There is need to convert the dem to ellipsoid if it is in geoid\n\n\n    #call asp pc_align function on road and DEM and output translation/rotation matrix\n    align_pc = join(in_dir,'pc-align', basename(align_path)) #set the align files name format\n    pc_align_func = join(asp_dir, 'pc_align') #set the path to the pc_align function\n    subprocess.run([pc_align_func, '--max-displacement', '5', '--highest-accuracy', ref_dem, clipped_pc, '-o', align_pc]) #run the pc_align function\n\n    # Apply transformation matrix to the entire laz and output points\n    initial_tansform = align_pc +  '-transform.txt' #set the transform files name format\n    transform_pc = join(in_dir,'pc-transform', basename(align_path))\n    subprocess.run([pc_align_func, '--max-displacement', '-1', '--num-iterations', '0', '--initial-transform', \n                    initial_tansform, '--save-transformed-source-points', ref_dem, laz_fp,'-o', transform_pc])\n    #print the command that was run\n    print([pc_align_func, '--max-displacement', '-1', '--num-iterations', '0', '--initial-transform', \n                    initial_tansform, '--save-transformed-source-points', ref_dem, laz_fp,'-o', transform_pc])\n\n    # Grid the output to a 0.5 meter tif (NOTE: this needs to be changed to 1m if using py3dep)\n    transform_laz = transform_pc + '-transform.laz'\n    point2dem_func = join(asp_dir, 'point2dem')\n    subprocess.run([point2dem_func, transform_laz,'--dem-spacing', '0.5', '--search-radius-factor', '2', '-o', align_path])\n\n    return align_path + '-DEM.tif'\n</code></pre>"},{"location":"align/#snow_pc.align.laz_align","title":"<code>laz_align(laz_fp, align_shp, asp_dir, buffer_width, dem_is_geoid=False)</code>","text":"<p>Clip the point cloud to a shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>description</p> required <code>buff_shp</code> <code>_type_</code> <p>description</p> required <code>dem_is_geoid</code> <code>_type_</code> <p>description</p> <code>False</code> <code>is_canopy</code> <code>bool</code> <p>description. Defaults to False.</p> required <p>Exceptions:</p> Type Description <code>Exception</code> <p>description</p> Source code in <code>snow_pc/align.py</code> <pre><code>def laz_align(laz_fp, align_shp, asp_dir, buffer_width, dem_is_geoid = False):\n    \"\"\"Clip the point cloud to a shapefile.\n\n    Args:\n        laz_fp (_type_): _description_\n        buff_shp (_type_): _description_\n        dem_is_geoid (_type_): _description_\n        is_canopy (bool, optional): _description_. Defaults to False.\n\n    Raises:\n        Exception: _description_\n    \"\"\"\n    #set the working directory\n    in_dir = dirname(laz_fp)\n\n    #create a buffer around the shapefile to clip the point cloud\n    gdf = gpd.read_file(align_shp)\n    gdf['geometry'] = gdf.geometry.buffer(buffer_width / 2) #The buffer_width is the entire width. So, must divide by 2 here to get the right distance from centerline.\n    gdf['CLS'] = 22 # Create a new attribute to be used for PDAL clip/overlay\n    buff_shp = join(in_dir, 'buffered_area.shp')\n    gdf.to_file(buff_shp)\n\n    #remove .tif of the laz_fp path and add -align to the end\n    align_path = laz_fp.replace('.laz', '-align')\n\n    #set asp_dir\n    if basename(asp_dir) != 'bin':\n        asp_dir = join(asp_dir, 'bin')\n\n    align_tif = clip_align(laz_fp, buff_shp=buff_shp, align_path= align_path,  asp_dir = asp_dir, dem_is_geoid = False)\n\n    return align_tif\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v010-mar-9-2024","title":"v0.1.0 Mar 9, 2024","text":"<p>New Features: - Added prepare module with replace_white_dir, las2laz and merge_laz_files function - Added filtering module with functions for all necessary filters and segmentation (return filter, dem filter, elm filter, outlier filter, ground segmentation and surface segmentation) - Added modeling module with terrain and surface model functions</p> <p>Improvement: - Fixed the snow_pc prepare_pc bugs - Improved the readme and the api documentation for the website  </p>"},{"location":"changelog/#v001-feb-10-2024","title":"v0.0.1 - Feb 10, 2024","text":"<ul> <li> <p>Created Documentation website</p> </li> <li> <p>Initial release</p> </li> </ul>"},{"location":"changelog/#v001-feb-9-2024","title":"v0.0.1 - Feb 9, 2024","text":"<ul> <li>Initial release</li> </ul>"},{"location":"common/","title":"common module","text":""},{"location":"common/#snow_pc.common.download_dem","title":"<code>download_dem(laz_fp, dem_fp, cache_fp='./cache/aiohttp_cache.sqlite')</code>","text":"<p>Download DEM within the bounds of the las file.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Path to the las file.</p> required <code>dem_fp</code> <code>str</code> <p>Filename for the downloaded dem. Defaults to 'dem.tif'.</p> required <code>cache_fp</code> <code>str</code> <p>Cache filepath. Defaults to './cache/aiohttp_cache.sqlite'.</p> <code>'./cache/aiohttp_cache.sqlite'</code> <p>Returns:</p> Type Description <code>_type_</code> <p>The filepath to the downloaded DEM, the crs of the las file, and the transform from the las crs to wgs84. </p> Source code in <code>snow_pc/common.py</code> <pre><code>def download_dem(laz_fp, dem_fp, cache_fp ='./cache/aiohttp_cache.sqlite'):\n    \"\"\"Download DEM within the bounds of the las file.\n\n    Args:\n        laz_fp (_type_): Path to the las file.\n        dem_fp (str, optional): Filename for the downloaded dem. Defaults to 'dem.tif'.\n        cache_fp (str, optional): Cache filepath. Defaults to './cache/aiohttp_cache.sqlite'.\n\n    Returns:\n        _type_: The filepath to the downloaded DEM, the crs of the las file, and the transform from the las crs to wgs84. \n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    # read crs of las file\n    with laspy.open(laz_fp) as las:\n        hdr = las.header\n        crs = hdr.parse_crs()\n    # log.debug(f\"CRS used is {crs}\")\n    # create transform from wgs84 to las crs\n    wgs84 = pyproj.CRS('EPSG:4326')\n    project = pyproj.Transformer.from_crs(crs, wgs84 , always_xy=True).transform\n    # calculate bounds of las file in wgs84\n    utm_bounds = box(hdr.mins[0], hdr.mins[1], hdr.maxs[0], hdr.maxs[1])\n    wgs84_bounds = transform(project, utm_bounds)\n    # download dem inside bounds\n    os.environ[\"HYRIVER_CACHE_NAME\"] = cache_fp\n\n    dem_wgs = py3dep.get_map('DEM', wgs84_bounds, resolution=1, crs='EPSG:4326')\n    # log.debug(f\"DEM bounds: {dem_wgs.rio.bounds()}. Size: {dem_wgs.size}\")\n    # reproject to las crs and save\n    dem_utm = dem_wgs.rio.reproject(crs, resampling = Resampling.cubic_spline)\n    dem_utm.rio.to_raster(dem_fp)\n    # log.debug(f\"Saved to {dem_fp}\")\n    return dem_fp, crs, project\n</code></pre>"},{"location":"common/#snow_pc.common.make_dirs","title":"<code>make_dirs(in_dir)</code>","text":"<p>Create directories for the laz file and the results.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Type Description <code>_type_</code> <p>description</p> Source code in <code>snow_pc/common.py</code> <pre><code>def make_dirs(in_dir):\n    \"\"\"Create directories for the laz file and the results.\n\n    Args:\n        laz_fp (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    # set up sub directories\n    snowpc_dir = os.path.join(in_dir, 'snow-pc')\n    os.makedirs(snowpc_dir, exist_ok= True)\n    results_dir = os.path.join(snowpc_dir, 'results')\n    os.makedirs(results_dir, exist_ok= True)\n    return results_dir\n</code></pre>"},{"location":"common/#snow_pc.common.snowdepth_val","title":"<code>snowdepth_val(lid_path, csv_path, snowdepth_col, lat_col, lon_col, csv_EPSG=4326, zone_utmcrs=32611, lid_unit='m', probe_unit='cm', use_buffer='no')</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>lid_path</code> <code>_type_</code> <p>description</p> required <code>csv_path</code> <code>_type_</code> <p>description</p> required <code>snowdepth_col</code> <code>_type_</code> <p>description</p> required <code>lat_col</code> <code>_type_</code> <p>description</p> required <code>lon_col</code> <code>_type_</code> <p>description</p> required <code>csv_EPSG</code> <code>int</code> <p>description. Defaults to 4326.</p> <code>4326</code> <code>zone_utmcrs</code> <code>int</code> <p>description. Defaults to 32611.</p> <code>32611</code> <code>lid_unit</code> <code>str</code> <p>description. Defaults to \"m\".</p> <code>'m'</code> <code>probe_unit</code> <code>str</code> <p>description. Defaults to \"cm\".</p> <code>'cm'</code> <code>use_buffer</code> <code>str</code> <p>description. Defaults to 'no'.</p> <code>'no'</code> <p>Returns:</p> Type Description <code>_type_</code> <p>description</p> Source code in <code>snow_pc/common.py</code> <pre><code>def snowdepth_val(lid_path, csv_path, snowdepth_col, lat_col, lon_col, csv_EPSG=4326, zone_utmcrs=32611, lid_unit=\"m\", probe_unit=\"cm\", use_buffer = 'no'):\n    \"\"\"_summary_\n\n    Args:\n        lid_path (_type_): _description_\n        csv_path (_type_): _description_\n        snowdepth_col (_type_): _description_\n        lat_col (_type_): _description_\n        lon_col (_type_): _description_\n        csv_EPSG (int, optional): _description_. Defaults to 4326.\n        zone_utmcrs (int, optional): _description_. Defaults to 32611.\n        lid_unit (str, optional): _description_. Defaults to \"m\".\n        probe_unit (str, optional): _description_. Defaults to \"cm\".\n        use_buffer (str, optional): _description_. Defaults to 'no'.\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    # read the lidar raster data\n    lidar = rxr.open_rasterio(lid_path, masked = True)\n    #reproject to crs of the zone\n    if lidar.rio.crs.to_string() != \"EPSG:\" + str(zone_utmcrs):\n        lidar = lidar.rio.reproject(CRS.from_string(\"EPSG:\" + str(zone_utmcrs)))\n    # read the csv\n    df = pd.read_csv(csv_path, usecols=[snowdepth_col, lat_col, lon_col])\n    # convert to geodataframe\n    gdf = gpd.GeoDataFrame(\n        df,\n        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n        crs=\"EPSG:\" + str(csv_EPSG),\n    )\n    # convert the gdf to crs of the zone\n    gdf_utm = gdf.to_crs(\"EPSG:\" + str(zone_utmcrs))\n\n    #Extract the LiDAR pixels at pixel or buffered region \n    if use_buffer == \"no\":\n        # sample the snow depth raster values at point locations\n        vals = point_query(gdf_utm.geometry, lidar.squeeze().values, affine = lidar.rio.transform(), nodata = -9999)\n        # add the values to a new column in the GeoDataFrame\n        gdf_utm['lidar'] = vals\n    else:\n        # buffer the points\n        gdf_utm_buffered = gdf_utm.buffer(2)\n        # calculate zonal statistics of the mean within the buffer\n        vals = zonal_stats(\n            gdf_utm_buffered,\n            lidar.squeeze().values,\n            affine=lidar.rio.transform(),\n            nodata=-9999,\n            stats=\"mean\",\n        )\n        # add the values to new columns in the GeoDataFrame\n        gdf_utm['lidar'] = [stat[\"mean\"] for stat in vals]\n\n    #convert the unit to m\n    if probe_unit == \"cm\":\n        gdf_utm[snowdepth_col] = gdf_utm[snowdepth_col] / 100\n    if lid_unit == \"cm\":\n        gdf_utm[\"lidar\"] = gdf_utm[\"lidar\"]/100\n    #rename the columns\n    gdf_utm.rename(columns={\n                       snowdepth_col: 'Probed Snow Depth (m)', 'lidar': 'LiDAR Snow Depth (m)'}, inplace=True)\n    #add error column\n    gdf_utm['error (cm)'] = (gdf_utm['Probed Snow Depth (m)'] - gdf_utm['LiDAR Snow Depth (m)']) * 100\n\n    #read the road shapefile\n    road = gpd.read_file('/SNOWDATA/IDALS/misc_data_scripts/3mroadBufferClip/3m_road.shp')\n    # convert the gdf to crs of the zone\n    road = road.to_crs(\"EPSG:\" + str(zone_utmcrs))\n    #create a 5m buffer\n    road_10 = road.buffer(2)\n    #sample lidar values overlapping with road_10\n    values = zonal_stats(\n            road_10,\n            lidar.squeeze().values,\n            affine=lidar.rio.transform(),\n            raster_out=True, stats=\"mean\"\n        )\n    masked_data = values[0]['mini_raster_array']\n    lidar_road = masked_data[~masked_data.mask] \n\n\n    return gdf_utm, lidar_road\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Surfix/snow-pc/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>snow-pc could always use more documentation, whether as part of the official snow-pc docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Surfix/snow-pc/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up snow-pc for local development.</p> <ol> <li> <p>Fork the snow-pc repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/snow-pc.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv snow-pc\n$ cd snow-pc/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 snow-pc tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy. Check https://github.com/Surfix/snow-pc/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"filtering/","title":"filtering module","text":""},{"location":"filtering/#snow_pc.filtering.dem_filtering","title":"<code>dem_filtering(laz_fp, user_dem='', dem_low=20, dem_high=50, out_fp='')</code>","text":"<p>Use filters.dem to filter the point cloud to the DEM. </p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <code>user_dem</code> <code>str</code> <p>Filepath to the DEM file. Defaults to ''.</p> <code>''</code> <code>dem_low</code> <code>int</code> <p>Lower limit of the DEM. Defaults to 20.</p> <code>20</code> <code>dem_high</code> <code>int</code> <p>Upper limit of the DEM. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the filtered point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def dem_filtering(laz_fp, user_dem = '', dem_low = 20, dem_high = 50, out_fp = ''):\n    \"\"\"Use filters.dem to filter the point cloud to the DEM. \n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n        user_dem (str, optional): Filepath to the DEM file. Defaults to ''.\n        dem_low (int, optional): Lower limit of the DEM. Defaults to 20.\n        dem_high (int, optional): Upper limit of the DEM. Defaults to 50.\n\n    Returns:\n        _type_: Filepath to the filtered point cloud file.\n    \"\"\"\n\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #set dem_fp\n    dem_fp = join(in_dir, 'dem.tif')\n\n    #download dem using download_dem() if user_dem is not provided\n    if user_dem == '':\n        dem_fp, crs, project = download_dem(laz_fp, dem_fp= dem_fp)\n    else:\n        shutil.copy(user_dem, dem_fp) #if user_dem is provided, copy the user_dem to dem_fp\n\n    #create a filepath for the output las file\n    if out_fp == '':\n        out_fp = \"dem_filtered.laz\"\n\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.dem\",\n                \"raster\": dem_fp,\n                \"limits\": f\"Z[{dem_low}:{dem_high}]\"\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'dem_filtering'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use], shell=True)\n\n    return out_fp\n</code></pre>"},{"location":"filtering/#snow_pc.filtering.elm_filtering","title":"<code>elm_filtering(laz_fp, out_fp='')</code>","text":"<p>Use filters.elm to filter the point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the filtered point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def elm_filtering(laz_fp, out_fp = ''):\n    \"\"\"Use filters.elm to filter the point cloud.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n\n    Returns:\n        _type_: Filepath to the filtered point cloud file.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #create a filepath for the output las file\n    if out_fp == '':\n        out_fp = \"elm_filtered.laz\"\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.elm\"\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'elm_filtering'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return out_fp\n</code></pre>"},{"location":"filtering/#snow_pc.filtering.ground_segmentation","title":"<code>ground_segmentation(laz_fp, out_fp='', out_fp2='')</code>","text":"<p>Use filters.smrf and filters.range to segment ground points.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the segmented point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def ground_segmentation(laz_fp, out_fp = '', out_fp2 = ''):\n    \"\"\"Use filters.smrf and filters.range to segment ground points.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n\n    Returns:\n        _type_: Filepath to the segmented point cloud file.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #create a filepath for the output laz and tif file\n    if out_fp == '':\n        out_fp = \"ground_segmented.laz\"\n    if out_fp2 == '':\n        out_fp2 = \"ground_segmented.tif\"\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.smrf\",\\\n                \"ignore\": \"Classification[7:7], NumberOfReturns[0:0], ReturnNumber[0:0]\"\n            },\n            {\n                \"type\": \"filters.range\",\n                \"limits\": \"Classification[2:2]\"\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            },\n            {\n                \"type\": \"writers.gdal\",\n                \"filename\": out_fp2,\n                \"resolution\": 1.0,\n                \"output_type\": \"idw\"\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'ground_segmentation'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return out_fp, out_fp2\n</code></pre>"},{"location":"filtering/#snow_pc.filtering.outlier_filtering","title":"<code>outlier_filtering(laz_fp, mean_k=20, multiplier=3, out_fp='')</code>","text":"<p>Use filters.outlier to filter the point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <code>mean_k</code> <code>int</code> <p>description. Defaults to 20.</p> <code>20</code> <code>multiplier</code> <code>int</code> <p>description. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the filtered point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def outlier_filtering(laz_fp, mean_k = 20, multiplier = 3, out_fp = ''):\n    \"\"\"Use filters.outlier to filter the point cloud.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n        mean_k (int, optional): _description_. Defaults to 20.\n        multiplier (int, optional): _description_. Defaults to 3.\n\n    Returns:\n        _type_: Filepath to the filtered point cloud file.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #create a filepath for the output las file\n    if out_fp == '':\n        out_fp = \"outlier_filtered.laz\"\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.outlier\",\\\n                \"method\": \"statistical\",\\\n                \"mean_k\": mean_k,\\\n                \"multiplier\": multiplier\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'outlier_filtering'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return out_fp\n</code></pre>"},{"location":"filtering/#snow_pc.filtering.return_filtering","title":"<code>return_filtering(laz_fp, out_fp='')</code>","text":"<p>Use filters.mongo to filter out points with invalid returns.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the filtered point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def return_filtering(laz_fp, out_fp = ''):\n    \"\"\"Use filters.mongo to filter out points with invalid returns.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n\n    Returns:\n        _type_: Filepath to the filtered point cloud file.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #create a filepath for the output las file\n    if out_fp == '':\n        out_fp = \"returns_filtered.laz\"\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.mongo\",\\\n                \"expression\": {\"$and\": [\\\n                {\"ReturnNumber\": {\"$gt\": 0}},\\\n                {\"NumberOfReturns\": {\"$gt\": 0}} ] }\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'return_filtering'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return out_fp\n</code></pre>"},{"location":"filtering/#snow_pc.filtering.surface_segmentation","title":"<code>surface_segmentation(laz_fp, out_fp='', out_fp2='')</code>","text":"<p>Use filters.range to segment the surface points.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the segmented point cloud file.</p> Source code in <code>snow_pc/filtering.py</code> <pre><code>def surface_segmentation(laz_fp, out_fp = '', out_fp2 = ''):\n    \"\"\"Use filters.range to segment the surface points.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n\n    Returns:\n        _type_: Filepath to the segmented point cloud file.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    os.chdir(in_dir)\n\n    #create a filepath for the output laz and tif file\n    if out_fp == '':\n        out_fp = \"surface_segmented.laz\"\n    if out_fp2 == '':\n        out_fp2 = \"surface_segmented.tif\"\n\n    #create a json pipeline for pdal\n    json_pipeline = {\n        \"pipeline\": [\n            {\n                \"type\": \"readers.las\",\n                \"filename\": laz_fp\n            },\n            {\n                \"type\": \"filters.range\",\n                \"limits\": \"returnnumber[1:1]\"\n            },\n            {\n                \"type\": \"writers.las\",\n                \"filename\": out_fp\n            },\n            {\n                \"type\": \"writers.gdal\",\n                \"filename\": out_fp2,\n                \"resolution\": 1.0,\n                \"output_type\": \"idw\"\n            }\n        ]\n    }\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'surface_segmentation'\n    json_to_use = join(json_dir, f'{json_name}.json')\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return out_fp, out_fp2\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install snow-pc, run this command in your terminal:</p> <pre><code>pip install snow-pc\n</code></pre> <p>This is the preferred method to install snow-pc, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install snow-pc from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/Surfix/snow-pc\n</code></pre>"},{"location":"modeling/","title":"modeling module","text":""},{"location":"modeling/#snow_pc.modeling.surface_models","title":"<code>surface_models(laz_fp, outlas='', outtif='', user_dem='', dem_low=20, dem_high=50, mean_k=20, multiplier=3, lidar_pc='yes')</code>","text":"<p>Use filters.dem, filters.mongo, filters.elm, filters.outlier, filters.smrf, and filters.range to filter the point cloud for surface models.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>description</p> required <code>outlas</code> <code>str</code> <p>description. Defaults to ''.</p> <code>''</code> <code>outtif</code> <code>str</code> <p>description. Defaults to ''.</p> <code>''</code> <code>user_dem</code> <code>str</code> <p>description. Defaults to ''.</p> <code>''</code> <code>dem_low</code> <code>int</code> <p>description. Defaults to 20.</p> <code>20</code> <code>dem_high</code> <code>int</code> <p>description. Defaults to 50.</p> <code>50</code> <code>mean_k</code> <code>int</code> <p>description. Defaults to 20.</p> <code>20</code> <code>multiplier</code> <code>int</code> <p>description. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the terrain model.</p> Source code in <code>snow_pc/modeling.py</code> <pre><code>def surface_models(laz_fp, outlas = '', outtif = '', user_dem = '', dem_low = 20, dem_high = 50, mean_k = 20, multiplier = 3, lidar_pc = 'yes'):\n    \"\"\"Use filters.dem, filters.mongo, filters.elm, filters.outlier, filters.smrf, and filters.range to filter the point cloud for surface models.\n\n    Args:\n        laz_fp (_type_): _description_\n        outlas (str, optional): _description_. Defaults to ''.\n        outtif (str, optional): _description_. Defaults to ''.\n        user_dem (str, optional): _description_. Defaults to ''.\n        dem_low (int, optional): _description_. Defaults to 20.\n        dem_high (int, optional): _description_. Defaults to 50.\n        mean_k (int, optional): _description_. Defaults to 20.\n        multiplier (int, optional): _description_. Defaults to 3.\n\n    Returns:\n        _type_: Filepath to the terrain model.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    # os.chdir(in_dir)\n\n    #create a filepath for the output las and tif file\n    if outlas == '':\n        outlas = join(in_dir, 'dsm.laz')\n    if outtif == '':\n        outtif = join(in_dir, 'dsm.tif')\n\n    #set dem_fp\n    dem_fp = join(in_dir, 'dem.tif')\n\n    #download dem using download_dem() if user_dem is not provided\n    if user_dem == '':\n        dem_fp, crs, project = download_dem(laz_fp, dem_fp= dem_fp)\n    else:\n        shutil.copy(user_dem, dem_fp) #if user_dem is provided, copy the user_dem to dem_fp \n\n    if lidar_pc.lower() == 'yes':\n        #create a json pipeline for pdal\n        json_pipeline = {\n            \"pipeline\": [\n                {\n                    \"type\": \"readers.las\",\n                    \"filename\": laz_fp\n                },\n                {\n                    \"type\": \"filters.dem\",\n                    \"raster\": dem_fp,\n                    \"limits\": f\"Z[{dem_low}:{dem_high}]\"\n                },\n                {\n                    \"type\": \"filters.mongo\",\\\n                    \"expression\": {\"$and\": [\\\n                    {\"ReturnNumber\": {\"$gt\": 0}},\\\n                    {\"NumberOfReturns\": {\"$gt\": 0}} ] }\n                },\n                {\n                    \"type\": \"filters.elm\"\n                },\n                {\n                    \"type\": \"filters.outlier\",\\\n                    \"method\": \"statistical\",\\\n                    \"mean_k\": mean_k,\\\n                    \"multiplier\": multiplier\n                },\n                {\"type\": \"filters.range\",\\\n                \"limits\":\"returnnumber[1:1]\"\n                },\n                {\n                    \"type\": \"writers.las\",\n                    \"filename\": outlas,\n                    \"major_version\": 1,\n                    \"minor_version\": 4\n                },\n                {\n                    \"type\": \"writers.gdal\",\n                    \"filename\": outtif,\n                    \"resolution\": 1.0,\n                    \"output_type\": \"idw\"\n                }\n            ]\n        }\n    else:\n        #create a json pipeline for pdal\n        json_pipeline = {\n            \"pipeline\": [\n                {\n                    \"type\": \"readers.las\",\n                    \"filename\": laz_fp\n                },\n                {\n                    \"type\": \"filters.dem\",\n                    \"raster\": dem_fp,\n                    \"limits\": f\"Z[{dem_low}:{dem_high}]\"\n                },\n                {\n                    \"type\": \"filters.elm\"\n                },\n                {\n                    \"type\": \"filters.outlier\",\\\n                    \"method\": \"statistical\",\\\n                    \"mean_k\": mean_k,\\\n                    \"multiplier\": multiplier\n                },\n                {\"type\": \"filters.range\",\\\n                \"limits\":\"Classification[2:6]\"\n                },\n                {\n                    \"type\": \"writers.las\",\n                    \"filename\": outlas,\n                    \"major_version\": 1,\n                    \"minor_version\": 4\n                },\n                {\n                    \"type\": \"writers.gdal\",\n                    \"filename\": outtif,\n                    \"resolution\": 1.0,\n                    \"output_type\": \"idw\"\n                }\n            ]\n        }\n\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'dsm_pipeline'\n    json_to_use = join(json_dir, f'{json_name}.json')\n\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return outlas, outtif\n</code></pre>"},{"location":"modeling/#snow_pc.modeling.terrain_models","title":"<code>terrain_models(laz_fp, outlas='', outtif='', user_dem='', dem_low=20, dem_high=50, mean_k=20, multiplier=3, lidar_pc='yes')</code>","text":"<p>Use filters.dem, filters.mongo, filters.elm, filters.outlier, filters.smrf, and filters.range to filter the point cloud for terrain models.</p> <p>Parameters:</p> Name Type Description Default <code>laz_fp</code> <code>_type_</code> <p>Filepath to the point cloud file.</p> required <code>outlas</code> <code>str</code> <p>Filepath to save the output las file. Defaults to ''.</p> <code>''</code> <code>outtif</code> <code>str</code> <p>Filepath to save the output tif file. Defaults to ''.</p> <code>''</code> <code>user_dem</code> <code>str</code> <p>Filepath to the dem file. Defaults to ''.</p> <code>''</code> <code>dem_low</code> <code>int</code> <p>description. Defaults to 20.</p> <code>20</code> <code>dem_high</code> <code>int</code> <p>description. Defaults to 50.</p> <code>50</code> <code>mean_k</code> <code>int</code> <p>description. Defaults to 20.</p> <code>20</code> <code>multiplier</code> <code>int</code> <p>description. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>_type_</code> <p>Filepath to the terrain model.</p> Source code in <code>snow_pc/modeling.py</code> <pre><code>def terrain_models(laz_fp, outlas = '', outtif = '', user_dem = '', dem_low = 20, dem_high = 50, mean_k = 20, multiplier = 3, lidar_pc = 'yes'):\n    \"\"\"Use filters.dem, filters.mongo, filters.elm, filters.outlier, filters.smrf, and filters.range to filter the point cloud for terrain models.\n\n    Args:\n        laz_fp (_type_): Filepath to the point cloud file.\n        outlas (str, optional): Filepath to save the output las file. Defaults to ''.\n        outtif (str, optional): Filepath to save the output tif file. Defaults to ''.\n        user_dem (str, optional): Filepath to the dem file. Defaults to ''.\n        dem_low (int, optional): _description_. Defaults to 20.\n        dem_high (int, optional): _description_. Defaults to 50.\n        mean_k (int, optional): _description_. Defaults to 20.\n        multiplier (int, optional): _description_. Defaults to 3.\n\n    Returns:\n        _type_: Filepath to the terrain model.\n    \"\"\"\n    #set the working directory\n    in_dir = os.path.dirname(laz_fp)\n    # os.chdir(in_dir)\n\n    #create a filepath for the output las and tif file\n    if outlas == '':\n        outlas = join(in_dir, 'dtm.laz')\n    if outtif == '':\n        outtif = join(in_dir, 'dtm.tif')\n\n    #set dem_fp\n    dem_fp = join(in_dir, 'dem.tif')\n\n    #download dem using download_dem() if user_dem is not provided\n    if user_dem == '':\n        dem_fp, crs, project = download_dem(laz_fp, dem_fp= dem_fp)\n    else:\n        shutil.copy(user_dem, dem_fp) #if user_dem is provided, copy the user_dem to dem_fp\n\n    if lidar_pc.lower() == 'yes':\n        #create a json pipeline for pdal\n        json_pipeline = {\n            \"pipeline\": [\n                {\n                    \"type\": \"readers.las\",\n                    \"filename\": laz_fp\n                },\n                {\n                    \"type\": \"filters.dem\",\n                    \"raster\": dem_fp,\n                    \"limits\": f\"Z[{dem_low}:{dem_high}]\"\n                },\n                {\n                    \"type\": \"filters.mongo\",\\\n                    \"expression\": {\"$and\": [\\\n                    {\"ReturnNumber\": {\"$gt\": 0}},\\\n                    {\"NumberOfReturns\": {\"$gt\": 0}} ] }\n                },\n                {\n                    \"type\": \"filters.elm\"\n                },\n                {\n                    \"type\": \"filters.outlier\",\\\n                    \"method\": \"statistical\",\\\n                    \"mean_k\": mean_k,\\\n                    \"multiplier\": multiplier\n                },\n                {\n                    \"type\": \"filters.smrf\",\\\n                    \"ignore\": \"Classification[7:7], NumberOfReturns[0:0], ReturnNumber[0:0]\"\n                },\n                {\n                    \"type\": \"filters.range\",\n                    \"limits\": \"Classification[2:2]\"\n                },\n                {\n                    \"type\": \"writers.las\",\n                    \"filename\": outlas,\n                    \"major_version\": 1,\n                    \"minor_version\": 4\n                },\n                {\n                    \"type\": \"writers.gdal\",\n                    \"filename\": outtif,\n                    \"resolution\": 1.0,\n                    \"output_type\": \"idw\"\n                }\n            ]\n        }\n    else: \n        #create a json pipeline for pdal\n        json_pipeline = {\n            \"pipeline\": [\n                {\n                    \"type\": \"readers.las\",\n                    \"filename\": laz_fp\n                },\n                {\n                    \"type\": \"filters.dem\",\n                    \"raster\": dem_fp,\n                    \"limits\": f\"Z[{dem_low}:{dem_high}]\"\n                },\n                {\n                    \"type\": \"filters.elm\"\n                },\n                {\n                    \"type\": \"filters.outlier\",\\\n                    \"method\": \"statistical\",\\\n                    \"mean_k\": mean_k,\\\n                    \"multiplier\": multiplier\n                },\n                # {\n                #     \"type\": \"filters.smrf\",\\\n                #     \"ignore\": \"Classification[7:7], NumberOfReturns[0:0], ReturnNumber[0:0]\"\n                # },\n                {\n                    \"type\": \"filters.range\",\n                    \"limits\": \"Classification[2:2]\"\n                },\n                {\n                    \"type\": \"writers.las\",\n                    \"filename\": outlas,\n                    \"major_version\": 1,\n                    \"minor_version\": 4\n                },\n                {\n                    \"type\": \"writers.gdal\",\n                    \"filename\": outtif,\n                    \"resolution\": 1.0,\n                    \"output_type\": \"idw\"\n                }\n            ]\n        }\n\n    #create a directory to save the json pipeline\n    json_dir =  join(in_dir, 'jsons')\n    os.makedirs(json_dir, exist_ok= True)\n    json_name = 'dtm_pipeline'\n    json_to_use = join(json_dir, f'{json_name}.json')\n\n    #write json pipeline to file\n    with open(json_to_use, 'w') as f:\n        json.dump(json_pipeline, f)\n\n    #run the json pipeline\n    subprocess.run([\"pdal\", \"pipeline\", json_to_use])\n\n    return outlas, outtif\n</code></pre>"},{"location":"prepare/","title":"prepare module","text":""},{"location":"prepare/#snow_pc.prepare.las2laz","title":"<code>las2laz(in_dir)</code>","text":"<p>Convert all LAS files in a directory to LAZ files.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>The directory containing the LAS files to convert.</p> required Source code in <code>snow_pc/prepare.py</code> <pre><code>def las2laz(in_dir: str):\n    \"\"\"Convert all LAS files in a directory to LAZ files.\n\n    Args:\n        in_dir (str): The directory containing the LAS files to convert.\n    \"\"\"\n\n    assert isdir(in_dir), f'{in_dir} is not a directory'\n\n    # Get a list of all LAS files in the directory\n    las_files = [file for file in os.listdir(in_dir) if file.endswith('.las')]\n\n    # Iterate over each LAS file and convert it to LAZ\n    for las_file in las_files:\n        input_path = os.path.join(in_dir, las_file)\n        output_path = os.path.join(in_dir, os.path.splitext(las_file)[0] + '.laz')\n        subprocess.run(['pdal', 'translate', input_path, output_path])\n        print(f\"Converted {input_path} to {output_path}\")\n</code></pre>"},{"location":"prepare/#snow_pc.prepare.merge_laz_files","title":"<code>merge_laz_files(in_dir, out_fp='unaligned_merged.laz')</code>","text":"<p>Merge all LAZ files in a directory into a single LAZ file.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>_type_</code> <p>Directory containing the LAZ files to merge.</p> required <code>out_fp</code> <code>str</code> <p>Filename of the merged LAZ file. Defaults to 'unaligned_merged.laz'.</p> <code>'unaligned_merged.laz'</code> Source code in <code>snow_pc/prepare.py</code> <pre><code>def merge_laz_files(in_dir, out_fp = 'unaligned_merged.laz'):\n    \"\"\"Merge all LAZ files in a directory into a single LAZ file.\n    Args:\n        in_dir (_type_): Directory containing the LAZ files to merge.\n        out_fp (str, optional): Filename of the merged LAZ file. Defaults to 'unaligned_merged.laz'.\n    \"\"\"\n    assert isdir(in_dir), f'{in_dir} is not a directory'\n    # out fp to save to\n    mosaic_fp = join(in_dir, out_fp)\n    # Get a list of all LAZ files in the directory\n    laz_files = [file for file in os.listdir(in_dir) if file.endswith('.laz')]\n\n    # Build the command to merge all LAZ files into a single file\n    command = ['pdal', 'merge']\n    for laz_file in laz_files:\n        command.append(os.path.join(in_dir, laz_file))\n    command.append(mosaic_fp)\n\n    # Execute the merge command\n    print(f'Running command: {command}')\n    subprocess.run(command)\n    print(f\"Merged {len(laz_files)} LAZ files into {mosaic_fp}\")\n</code></pre>"},{"location":"prepare/#snow_pc.prepare.prepare_pc","title":"<code>prepare_pc(in_dir, replace='')</code>","text":"<p>Prepare point cloud data for processing.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Path to the directory containing the point cloud files.</p> required <code>replace</code> <code>str</code> <p>Character to replace the white space. Defaults to ''.</p> <code>''</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the merged LAZ file.</p> Source code in <code>snow_pc/prepare.py</code> <pre><code>def prepare_pc(in_dir: str, replace: str = ''):\n    \"\"\"Prepare point cloud data for processing.\n\n    Args:\n        in_dir (str): Path to the directory containing the point cloud files.\n        replace (str, optional): Character to replace the white space. Defaults to ''.\n\n    Returns:\n        str: Path to the merged LAZ file.\n    \"\"\"\n\n    # checks on directory and user update\n    assert isdir(in_dir), f'Provided: {in_dir} is not a directory. Provide directory with .laz files.'\n\n    #checks if there is at least one file in the directory\n    assert len(glob(join(in_dir, '*'))) &gt; 0, f'No files found in {in_dir}'\n\n    #change to the directory\n    print(f\"Working in directory: {in_dir}\")\n    os.chdir(in_dir)\n\n    # set up sub directories\n    results_dir = make_dirs(in_dir)\n\n    #check and replace white spaces in file paths\n    for file in glob(join(in_dir, '*')):\n        if ' ' in file:\n            print('White spaces found in file paths. Removing...')\n            replace_white_spaces(in_dir, replace)\n            break\n\n    #check and convert all LAS files to LAZ\n    for file in glob(join(in_dir, '*')):\n        if file.endswith('.las'):\n            print('LAS files found. Converting to LAZ...')\n            las2laz(in_dir)\n            break\n\n    # mosaic\n    # if there is more than 1 laz file, merge them\n    if len(glob(join(in_dir, '*.laz'))) &gt; 1:\n        print('Merging LAZ files...')\n        mosaic_fp = os.path.join(results_dir, 'unfiltered_merge.laz')\n        merge_laz_files(in_dir, out_fp= mosaic_fp)\n        if os.path.exists(mosaic_fp):\n            return mosaic_fp\n        else:\n            print(f\"Error: Mosaic file not created\")\n    #if there is 1 laz file, copy it to the results directory named unfiltered.laz and return the path\n    else:\n        laz_fp = glob(join(in_dir, '*.laz'))[0]\n        shutil.copy(laz_fp, join(results_dir, 'unfiltered.laz'))\n        return join(results_dir, 'unfiltered.laz')\n</code></pre>"},{"location":"prepare/#snow_pc.prepare.replace_white_spaces","title":"<code>replace_white_spaces(in_dir, replace='')</code>","text":"<p>Remove any white space in the point cloud files. </p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>_type_</code> <p>in_dir directory of the point cloud files.</p> required <code>replace</code> <code>str</code> <p>Character to replace the white space. Defaults to ''.</p> <code>''</code> Source code in <code>snow_pc/prepare.py</code> <pre><code>def replace_white_spaces(in_dir, replace = ''):\n    \"\"\"Remove any white space in the point cloud files. \n\n    Args:\n        in_dir (_type_): in_dir directory of the point cloud files.\n        replace (str, optional): Character to replace the white space. Defaults to ''.\n    \"\"\"\n    assert isdir(in_dir), f'{in_dir} is not a directory'\n    response = input(f'Warning! About to replace whitespaces with \"{replace}\"s in {os.path.abspath(in_dir)} \\n Press y to continue...')\n    if response.lower() == 'y':\n        for path, folders, files in os.walk(in_dir):\n            for f in files:\n                os.rename(os.path.join(path, f), os.path.join(path, f.replace(' ', replace)))\n            for i in range(len(folders)):\n                new_name = folders[i].replace(' ', replace)\n                os.rename(os.path.join(path, folders[i]), os.path.join(path, new_name))\n                folders[i] = new_name\n    else:\n        print(f'Passing...')\n</code></pre>"},{"location":"snow_pc/","title":"snow_pc module","text":"<p>Main module.</p>"},{"location":"snow_pc/#snow_pc.snow_pc.pc2correctedDEM","title":"<code>pc2correctedDEM(in_dir, align_shp, asp_dir, user_dem='', buffer_width=3)</code>","text":"<p>Converts laz files to corrected DEM.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Path to the directory containing the point cloud files.</p> required <code>align_shp</code> <code>str</code> <p>Path to the shapefile to align the point cloud to.</p> required <code>user_dem</code> <code>str</code> <p>Path to the DEM file. Defaults to ''.</p> <code>''</code> <p>outtif (str): filepath to output DTM tiff outlas (str): filepath to output DTM laz file</p> Source code in <code>snow_pc/snow_pc.py</code> <pre><code>def pc2correctedDEM(in_dir, align_shp, asp_dir, user_dem = '', buffer_width= 3 ):\n    \"\"\"Converts laz files to corrected DEM.\n\n    Args:\n        in_dir (str): Path to the directory containing the point cloud files.\n        align_shp (str): Path to the shapefile to align the point cloud to.\n        user_dem (str, optional): Path to the DEM file. Defaults to ''.\n\n    Returns:\n    outtif (str): filepath to output DTM tiff\n    outlas (str): filepath to output DTM laz file\n    \"\"\"\n\n\n    # create uncorrected DEM\n    dtm_laz, dtm_tif, dsm_laz, dsm_tif = pc2uncorrectedDEM(in_dir, user_dem = user_dem)\n\n\n    # align the point cloud\n    dtm_align_tif = laz_align(dtm_laz, align_shp = align_shp, asp_dir= asp_dir, buffer_width= buffer_width)\n    dsm_align_tif = laz_align(dsm_laz, align_shp = align_shp, asp_dir= asp_dir, buffer_width= buffer_width)\n\n    return dtm_align_tif, dsm_align_tif\n</code></pre>"},{"location":"snow_pc/#snow_pc.snow_pc.pc2snow","title":"<code>pc2snow(in_dir, align_shp, asp_dir, user_dem='', buffer_width=3)</code>","text":"<p>Converts laz files to snow depth and canopy height.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Path to the directory containing the point cloud files.</p> required <code>align_shp</code> <code>str</code> <p>Path to the shapefile to align the point cloud to.</p> required <code>user_dem</code> <code>str</code> <p>Path to the DEM file. Defaults to ''.</p> <code>''</code> <p>outtif (str): filepath to output DTM tiff outlas (str): filepath to output DTM laz file</p> Source code in <code>snow_pc/snow_pc.py</code> <pre><code>def pc2snow(in_dir, align_shp, asp_dir, user_dem = '', buffer_width= 3):\n    \"\"\"Converts laz files to snow depth and canopy height.\n\n    Args:\n        in_dir (str): Path to the directory containing the point cloud files.\n        align_shp (str): Path to the shapefile to align the point cloud to.\n        user_dem (str, optional): Path to the DEM file. Defaults to ''.\n\n    Returns:\n    outtif (str): filepath to output DTM tiff\n    outlas (str): filepath to output DTM laz file\n    \"\"\"\n\n    # create corrected DEM\n    dtm_align_tif, dsm_align_tif = pc2correctedDEM(in_dir, align_shp, asp_dir, user_dem = user_dem, buffer_width= buffer_width)\n\n    #set dem_fp\n    in_dir = os.path.dirname(dtm_align_tif)\n    ref_dem_path = join(in_dir, 'dem.tif')\n\n    #create snow depth\n    snow_depth_path = join(in_dir, f'{basename(in_dir)}-snowdepth.tif')\n    snowoff = rio.open_rasterio(ref_dem_path, masked=True)\n    snowon = rio.open_rasterio(dtm_align_tif, masked=True) \n    snowon_matched = snowon.rio.reproject_match(snowoff)\n    snowdepth = snowon_matched - snowoff\n    snowdepth.rio.to_raster(snow_depth_path)\n\n    #create canopy height\n    canopy_height_path = join(in_dir, f'{basename(in_dir)}-canopyheight.tif')\n    canopy_height = rio.open_rasterio(dsm_align_tif, masked=True) - snowoff\n    canopy_height.rio.to_raster(canopy_height_path)\n\n    return snow_depth_path, canopy_height_path\n\n\n# class Map(ipyleaflet.Map):\n#     \"\"\"Custom map class that inherits from ipyleaflet.Map.\n#     \"\"\"\n#     def __init__(self, *args, **kwargs):\n\n#         if \"scroll_wheel_zoom\" not in kwargs:\n#             kwargs[\"scroll_wheel_zoom\"] = True\n#         super().__init__(*args, **kwargs)\n\n#         if \"layers_control\" not in kwargs:\n#             kwargs[\"layers_control\"] = True\n\n#         if kwargs[\"layers_control\"]:\n#             self.add_LayerControl()\n\n#         if \"fullscreen_control\" not in kwargs:\n#             kwargs[\"fullscreen_control\"] = True\n\n#         if kwargs[\"fullscreen_control\"]:\n#             self.add_fullscreen_control()            \n\n#     def add_search_control(self, position = \"topleft\", **kwargs):\n#         \"\"\"Add a search control to the map.\n\n#         Args:\n#             position (str, optional): Position of the search control. Defaults to \"topleft\".\n\n#         Returns:\n#             _type_: SearchControl object.\n#         \"\"\"\n#         if \"url\" not in kwargs:\n#             kwargs[\"url\"] = \"https://nominatim.openstreetmap.org/search?format=json&amp;q={s}\"\n#         search = ipyleaflet.SearchControl(position = position, **kwargs)\n#         self.add_control(search)\n#         return search\n\n#     def add_LayerControl(self, position = \"topright\"):\n#         \"\"\"Add a layer control to the map.\n\n#         Args:\n#             position (str, optional): Position of the layer control. Defaults to \"topright\".\n\n#         Returns:\n#             _type_: LayerControl object.\n#         \"\"\"\n#         layer_control = ipyleaflet.LayersControl(position = position)\n#         self.add_control(layer_control)\n#         return layer_control\n\n#     def add_fullscreen_control(self, position = \"topright\"):\n#         \"\"\"Add a fullscreen control to the map.\n\n#         Args:\n#             position (str, optional): Position of the fullscreen control. Defaults to \"topright\".\n\n#         Returns:\n#             _type_: FullscreenControl object.\n#         \"\"\"\n#         fullscreen = ipyleaflet.FullScreenControl(position = position)\n#         self.add_control(fullscreen)\n#         return fullscreen\n\n#     def add_tile_layer(self, url, name, **kwargs):\n#         \"\"\"Add a tile layer to the map.\n\n#         Args:\n#             url (str): URL of the tile layer.\n\n#         Returns:\n#             _type_: TileLayer object.\n#         \"\"\"\n#         tile_layer = ipyleaflet.TileLayer(url = url, name=name, **kwargs)\n#         self.add_layer(tile_layer)\n#         return tile_layer\n\n#     def add_basemap(self, basemap, **kwargs):\n#         \"\"\"Add a basemap to the map.\n\n#         Args:\n#             basemap (_type_): A string representing the basemap to add.\n\n#         Raises:\n#             ValueError: If the basemap is not recognized.\n#         \"\"\"\n#         import xyzservices.providers as xyz\n#         if basemap.lower() == \"openstreetmap\":\n#             url = \"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\"\n#             self.add_tile_layer(url, name = basemap,**kwargs)\n#         elif basemap.lower() == \"stamen terrain\":\n#             url = \"https://stamen-tiles-{s}.a.ssl.fastly.net/terrain/{z}/{x}/{y}.png\"\n#             self.add_tile_layer(url, name = basemap,**kwargs)\n#         elif basemap.lower() == \"opentopomap\":\n#             url = \"https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png\"\n#             self.add_tile_layer(url, name = basemap,**kwargs)\n#         elif basemap.lower() == \"satellite\":\n#             url = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n#             self.add_tile_layer(url, name = basemap,**kwargs)\n\n#         else:\n#             try:\n#                 basemap = eval(f\"xyz.{basemap}\")\n#                 url = basemap.build_url()\n#                 name = basemap[\"name\"]\n#                 attribute = basemap[\"attribution\"]\n#                 print(url, name)\n#                 self.add_tile_layer(url, name, attribution = attribute, **kwargs)\n#             except:\n#                 raise ValueError(f\"Basemap {basemap} not recognized.\")\n\n#     def add_geojson(self, data, name = \"geojson\", **kwargs):\n#         \"\"\"Add a GeoJSON layer to the map.\n\n#         Args:\n#             data (_type_): A GeoJSON object.\n\n#         Returns:\n#             _type_: GeoJSON object.\n#         \"\"\"\n\n#         if isinstance(data, str):\n#             import json\n#             with open(data, 'r') as f:\n#                 data = json.load(f)\n#         geojson = ipyleaflet.GeoJSON(data = data, name = name, **kwargs)\n#         self.add_layer(geojson)\n#         return geojson\n\n#     def add_shp(self, data, name = \"shapefile\", **kwargs):\n        # \"\"\"Add a shapefile to the map.\n\n        # Args:\n        #     data (_type_): A shapefile object.\n\n        # Returns:\n        #     _type_: GeoData object.\n        # \"\"\"\n        # gdf = gpd.read_file(data)\n        # geojson = gdf.__geo_interface__\n        # self.add_geojson(geojson, name = name, **kwargs)\n</code></pre>"},{"location":"snow_pc/#snow_pc.snow_pc.pc2uncorrectedDEM","title":"<code>pc2uncorrectedDEM(in_dir, outlas='', outtif='', user_dem='', dem_low=20, dem_high=50, mean_k=20, multiplier=3, lidar_pc='yes')</code>","text":"<p>Converts laz files to uncorrected DEM.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Path to the directory containing the point cloud files.</p> required <code>user_dem</code> <code>str</code> <p>Path to the DEM file. Defaults to ''.</p> <code>''</code> <p>outtif (str): filepath to output DTM tiff outlas (str): filepath to output DTM laz file</p> Source code in <code>snow_pc/snow_pc.py</code> <pre><code>def pc2uncorrectedDEM(in_dir, outlas = '', outtif = '', user_dem = '', dem_low = 20, dem_high = 50, mean_k = 20, multiplier = 3, lidar_pc = 'yes'):\n    \"\"\"Converts laz files to uncorrected DEM.\n\n    Args:\n        in_dir (str): Path to the directory containing the point cloud files.\n        user_dem (str, optional): Path to the DEM file. Defaults to ''.\n\n    Returns:\n    outtif (str): filepath to output DTM tiff\n    outlas (str): filepath to output DTM laz file\n    \"\"\"\n\n    # prepare point cloud\n    unfiltered_laz = prepare_pc(in_dir)\n\n    #create uncorrected DTM\n    dtm_laz, dtm_tif = terrain_models(unfiltered_laz, outtif= outtif, outlas= outlas, user_dem = user_dem, dem_low = dem_low, dem_high = dem_high, mean_k = mean_k, multiplier = multiplier, lidar_pc = lidar_pc)\n\n    #create uncorrected DSM\n    dsm_laz, dsm_tif = surface_models(unfiltered_laz, outtif= outtif, outlas= outlas, user_dem = user_dem, dem_low = dem_low, dem_high = dem_high, mean_k = mean_k, multiplier = multiplier, lidar_pc = lidar_pc)\n\n    return dtm_laz, dtm_tif, dsm_laz, dsm_tif\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use snow-pc in a project:</p> <pre><code>import snow_pc\n</code></pre>"},{"location":"examples/notebooks/align/","title":"Align","text":"In\u00a0[1]: Copied! <pre>from snow_pc.align import clip_align, laz_align\n</pre> from snow_pc.align import clip_align, laz_align In\u00a0[1]: Copied! <pre># laz_fp = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS/snow-pc/results/dtm.laz'\n# align_shp = '/home/naheemadebisi/nfs_home/snow-analytics/snow-pc/transform_area/hwy_21/hwy21_utm_edit_v3.shp'\n# asp_dir = '/SNOWDATA/IDALS/ASP'\n# print(asp_dir)\n</pre> # laz_fp = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS/snow-pc/results/dtm.laz' # align_shp = '/home/naheemadebisi/nfs_home/snow-analytics/snow-pc/transform_area/hwy_21/hwy21_utm_edit_v3.shp' # asp_dir = '/SNOWDATA/IDALS/ASP' # print(asp_dir)  In\u00a0[2]: Copied! <pre># laz_align(laz_fp, align_shp, asp_dir)\n</pre> # laz_align(laz_fp, align_shp, asp_dir) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/notebooks/filtering/","title":"Filtering","text":"In\u00a0[1]: Copied! <pre>from snow_pc.filtering import return_filtering, elm_filtering, outlier_filtering, dem_filtering, ground_segmentation\n</pre> from snow_pc.filtering import return_filtering, elm_filtering, outlier_filtering, dem_filtering, ground_segmentation <p>Workflow</p> <ul> <li>return filtering</li> <li>dem filtering</li> <li>elm filtering</li> <li>outlier filtering</li> <li>smrf</li> </ul> In\u00a0[5]: Copied! <pre># return_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\unfiltered_merge.laz')\n</pre> # return_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\unfiltered_merge.laz') Out[5]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\returns_filtered.laz'</pre> In\u00a0[6]: Copied! <pre># dem_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\returns_filtered.laz', r\"C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif\", dem_low= 10, dem_high=50)\n</pre> # dem_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\returns_filtered.laz', r\"C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif\", dem_low= 10, dem_high=50) Out[6]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\dem_filtered.laz'</pre> In\u00a0[7]: Copied! <pre># elm_filtering('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\dem_filtered.laz')\n</pre> # elm_filtering('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\dem_filtered.laz') Out[7]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\elm_filtered.laz'</pre> In\u00a0[8]: Copied! <pre># outlier_filtering('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\elm_filtered.laz', multiplier=2.5)\n</pre> # outlier_filtering('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\elm_filtered.laz', multiplier=2.5) Out[8]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\outlier_filtered.laz'</pre> In\u00a0[4]: Copied! <pre># dem_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\outlier_filtered.laz', r\"C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif\", dem_low= 10, dem_high=50)\n</pre> # dem_filtering(r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore\\20240213_MCS_Pre\\snow-pc\\results\\outlier_filtered.laz', r\"C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif\", dem_low= 10, dem_high=50) Out[4]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\dem_filtered.laz'</pre> In\u00a0[2]: Copied! <pre># ground_segmentation('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\outlier_filtered.laz')\n</pre> # ground_segmentation('C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\outlier_filtered.laz') Out[2]: <pre>'C:\\\\Users\\\\naheemadebisi\\\\Downloads\\\\dev_work\\\\explore\\\\20240213_MCS_Pre\\\\snow-pc\\\\results\\\\ground_segmented.laz'</pre>"},{"location":"examples/notebooks/modelling/","title":"Modelling","text":"In\u00a0[2]: Copied! <pre>from snow_pc.modeling import terrain_models, surface_models\nimport leafmap\n</pre> from snow_pc.modeling import terrain_models, surface_models import leafmap In\u00a0[19]: Copied! <pre># laz_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore_data\\20240213_MCS_Pre_1\\20240213_v1-240213_190028_Scanner_1.laz'\n# dem_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif'\n</pre> # laz_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore_data\\20240213_MCS_Pre_1\\20240213_v1-240213_190028_Scanner_1.laz' # dem_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif' In\u00a0[21]: Copied! <pre># leafmap.view_lidar(laz_fp)\n</pre> # leafmap.view_lidar(laz_fp) In\u00a0[20]: Copied! <pre># dtm_laz, dtm_tif = terrain_models(laz_fp, dem_fp = dem_fp)\n# dsm_laz, dsm_tif = surface_models(laz_fp, dem_fp = dem_fp)\n</pre> # dtm_laz, dtm_tif = terrain_models(laz_fp, dem_fp = dem_fp) # dsm_laz, dsm_tif = surface_models(laz_fp, dem_fp = dem_fp)  In\u00a0[24]: Copied! <pre># laz_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore_data\\20231113\\20231113_MCS_UPS\\20231113_UPS_shifted.laz'\n# dem_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif'\n</pre> # laz_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\explore_data\\20231113\\20231113_MCS_UPS\\20231113_UPS_shifted.laz' # dem_fp = r'C:\\Users\\naheemadebisi\\Downloads\\dev_work\\dem.tif' In\u00a0[1]: Copied! <pre># leafmap.view_lidar(laz_fp)\n</pre> # leafmap.view_lidar(laz_fp) In\u00a0[26]: Copied! <pre># dtm_laz, dtm_tif = terrain_models(laz_fp, dem_fp = dem_fp)\n# dsm_laz, dsm_tif = surface_models(laz_fp, dem_fp = dem_fp)\n</pre> # dtm_laz, dtm_tif = terrain_models(laz_fp, dem_fp = dem_fp) # dsm_laz, dsm_tif = surface_models(laz_fp, dem_fp = dem_fp)"},{"location":"examples/notebooks/modelling/#photogrammetry-point-clouds","title":"Photogrammetry point clouds\u00b6","text":""},{"location":"examples/notebooks/snow_py/","title":"Snow py","text":"In\u00a0[3]: Copied! <pre>from snow_pc import pc2uncorrectedDEM, pc2correctedDEM\n</pre> from snow_pc import pc2uncorrectedDEM, pc2correctedDEM In\u00a0[4]: Copied! <pre># in_dir = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS'\n# dem_fp = '/SNOWDATA/IDALS/REF_DEM/MCS_REFDEM_WGS84.tif'\n\n# dtm_laz, dtm_tif, dsm_laz, dsm_tif = pc2uncorrectedDEM(in_dir, user_dem = dem_fp)\n</pre> # in_dir = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS' # dem_fp = '/SNOWDATA/IDALS/REF_DEM/MCS_REFDEM_WGS84.tif'  # dtm_laz, dtm_tif, dsm_laz, dsm_tif = pc2uncorrectedDEM(in_dir, user_dem = dem_fp) In\u00a0[1]: Copied! <pre># in_dir = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS'\n# dem_fp = '/SNOWDATA/IDALS/REF_DEM/MCS_REFDEM_WGS84.tif'\n# align_shp = '/home/naheemadebisi/nfs_home/snow-analytics/snow-pc/transform_area/hwy_21/hwy21_utm_edit_v3.shp'\n# asp_dir = '/SNOWDATA/IDALS/ASP'\n\n# pc2correctedDEM(in_dir, align_shp, asp_dir, user_dem = dem_fp)\n</pre> # in_dir = '/SNOWDATA/IDALS/2024/20231113/20231113_MCS_ULS' # dem_fp = '/SNOWDATA/IDALS/REF_DEM/MCS_REFDEM_WGS84.tif' # align_shp = '/home/naheemadebisi/nfs_home/snow-analytics/snow-pc/transform_area/hwy_21/hwy21_utm_edit_v3.shp' # asp_dir = '/SNOWDATA/IDALS/ASP'  # pc2correctedDEM(in_dir, align_shp, asp_dir, user_dem = dem_fp) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}